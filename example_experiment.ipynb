{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:active_learning]",
      "language": "python",
      "name": "conda-env-active_learning-py"
    },
    "colab": {
      "name": "06_example_experiment.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgCBON9k7jmh"
      },
      "source": [
        "# Example Experiment\n",
        "> Experiment using Repeated MNIST and BatchBALD vs BALD vs random sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32FY7Oje7jmk"
      },
      "source": [
        "This notebook ties everything together and runs an AL loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXwmk9MQ7k08"
      },
      "source": [
        "!pip install -q git+https://github.com/BlackHC/batchbald_redux.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11zDFCFP7jmk"
      },
      "source": [
        "# experiment\n",
        "\n",
        "import blackhc.project.script\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz0eIj3m7jmm"
      },
      "source": [
        "# experiment\n",
        "\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from batchbald_redux import (\n",
        "    active_learning,\n",
        "    batchbald,\n",
        "    consistent_mc_dropout,\n",
        "    joint_entropy,\n",
        "    repeated_mnist,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j9hRiB_7jmm"
      },
      "source": [
        "Let's define our Bayesian CNN model that we will use to train MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feuikDJD7jmn"
      },
      "source": [
        "# experiment\n",
        "\n",
        "\n",
        "class BayesianCNN(consistent_mc_dropout.BayesianModule):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
        "        self.conv1_drop = consistent_mc_dropout.ConsistentMCDropout2d()\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
        "        self.conv2_drop = consistent_mc_dropout.ConsistentMCDropout2d()\n",
        "        self.fc1 = nn.Linear(1024, 128)\n",
        "        self.fc1_drop = consistent_mc_dropout.ConsistentMCDropout()\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def mc_forward_impl(self, input: torch.Tensor):\n",
        "        input = F.relu(F.max_pool2d(self.conv1_drop(self.conv1(input)), 2))\n",
        "        input = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(input)), 2))\n",
        "        input = input.view(-1, 1024)\n",
        "        input = F.relu(self.fc1_drop(self.fc1(input)))\n",
        "        input = self.fc2(input)\n",
        "        input = F.log_softmax(input, dim=1)\n",
        "\n",
        "        return input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUeIAgOS7jmn"
      },
      "source": [
        "Grab our dataset, we'll use Repeated-MNIST. We will acquire to samples for each class for our initial training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzLPpiCK7jmo"
      },
      "source": [
        "# experiment\n",
        "\n",
        "train_dataset, test_dataset = repeated_mnist.create_repeated_MNIST_dataset(num_repetitions=1, add_noise=False)\n",
        "\n",
        "num_initial_samples = 20\n",
        "num_classes = 10\n",
        "\n",
        "initial_samples = active_learning.get_balanced_sample_indices(\n",
        "    repeated_mnist.get_targets(train_dataset), num_classes=num_classes, n_per_digit=num_initial_samples / num_classes\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWgpRYnu7jmo"
      },
      "source": [
        "For this example, we are going to take two shortcuts that will reduce the performance:\n",
        "* we discard most of the training set and only keep 20k samples; and\n",
        "* we don't implement early stopping or epoch-wise training.\n",
        "\n",
        "Instead, we always train by drawing 24576 many samples from the training set. This will overfit in the beginning and underfit later, but it still is sufficient to achieve 90% accuracy with 105 samples in the training set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWP1fSaN7jmp"
      },
      "source": [
        "# experiment\n",
        "max_training_samples = 150\n",
        "acquisition_batch_size = 5\n",
        "num_inference_samples = 100\n",
        "num_test_inference_samples = 5\n",
        "num_samples = 100000\n",
        "\n",
        "test_batch_size = 512\n",
        "batch_size = 64\n",
        "scoring_batch_size = 128\n",
        "training_iterations = 4096 * 6\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "print(f\"use_cuda: {use_cuda}\")\n",
        "\n",
        "device = \"cuda\" if use_cuda else \"cpu\"\n",
        "\n",
        "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, **kwargs)\n",
        "\n",
        "active_learning_data = active_learning.ActiveLearningData(train_dataset)\n",
        "\n",
        "# Split off the initial samples first.\n",
        "active_learning_data.acquire(initial_samples)\n",
        "\n",
        "# THIS REMOVES MOST OF THE POOL DATA. UNCOMMENT THIS TO TAKE ALL UNLABELLED DATA INTO ACCOUNT!\n",
        "active_learning_data.extract_dataset_from_pool(40000)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    active_learning_data.training_dataset,\n",
        "    sampler=active_learning.RandomFixedLengthSampler(active_learning_data.training_dataset, training_iterations),\n",
        "    batch_size=batch_size,\n",
        "    **kwargs,\n",
        ")\n",
        "\n",
        "pool_loader = torch.utils.data.DataLoader(\n",
        "    active_learning_data.pool_dataset, batch_size=scoring_batch_size, shuffle=False, **kwargs\n",
        ")\n",
        "\n",
        "# Run experiment\n",
        "test_accs = []\n",
        "test_loss = []\n",
        "added_indices = []\n",
        "\n",
        "pbar = tqdm(initial=len(active_learning_data.training_dataset), total=max_training_samples, desc=\"Training Set Size\")\n",
        "\n",
        "while True:\n",
        "    model = BayesianCNN(num_classes).to(device=device)\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Train\n",
        "    for data, target in tqdm(train_loader, desc=\"Training\", leave=False):\n",
        "        data = data.to(device=device)\n",
        "        target = target.to(device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        prediction = model(data, 1).squeeze(1)\n",
        "        loss = F.nll_loss(prediction, target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Test\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
        "            data = data.to(device=device)\n",
        "            target = target.to(device=device)\n",
        "\n",
        "            prediction = torch.logsumexp(model(data, num_test_inference_samples), dim=1) - math.log(\n",
        "                num_test_inference_samples\n",
        "            )\n",
        "            loss += F.nll_loss(prediction, target, reduction=\"sum\")\n",
        "\n",
        "            prediction = prediction.max(1)[1]\n",
        "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
        "\n",
        "    loss /= len(test_loader.dataset)\n",
        "    test_loss.append(loss)\n",
        "\n",
        "    percentage_correct = 100.0 * correct / len(test_loader.dataset)\n",
        "    test_accs.append(percentage_correct)\n",
        "\n",
        "    print(\n",
        "        \"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\".format(\n",
        "            loss, correct, len(test_loader.dataset), percentage_correct\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if len(active_learning_data.training_dataset) >= max_training_samples:\n",
        "        break\n",
        "\n",
        "    # Acquire pool predictions\n",
        "    N = len(active_learning_data.pool_dataset)\n",
        "    logits_N_K_C = torch.empty((N, num_inference_samples, num_classes), dtype=torch.double, pin_memory=use_cuda)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        for i, (data, _) in enumerate(tqdm(pool_loader, desc=\"Evaluating Acquisition Set\", leave=False)):\n",
        "            data = data.to(device=device)\n",
        "\n",
        "            lower = i * pool_loader.batch_size\n",
        "            upper = min(lower + pool_loader.batch_size, N)\n",
        "            logits_N_K_C[lower:upper].copy_(model(data, num_inference_samples).double(), non_blocking=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        candidate_batch = batchbald.get_batchbald_batch(\n",
        "            logits_N_K_C, acquisition_batch_size, num_samples, dtype=torch.double, device=device\n",
        "        )\n",
        "\n",
        "    targets = repeated_mnist.get_targets(active_learning_data.pool_dataset)\n",
        "    dataset_indices = active_learning_data.get_dataset_indices(candidate_batch.indices)\n",
        "\n",
        "    print(\"Dataset indices: \", dataset_indices)\n",
        "    print(\"Scores: \", candidate_batch.scores)\n",
        "    print(\"Labels: \", targets[candidate_batch.indices])\n",
        "\n",
        "    active_learning_data.acquire(candidate_batch.indices)\n",
        "    added_indices.append(dataset_indices)\n",
        "    pbar.update(len(dataset_indices))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kmUGMsT7jmt"
      },
      "source": [
        "# hide\n",
        "# experiment\n",
        "test_accs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhUEMsrX7jmu"
      },
      "source": [
        "# hide\n",
        "# experiment\n",
        "test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6n1gxad7jmu"
      },
      "source": [
        "# hide\n",
        "# experiment\n",
        "added_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_UvYkk27jmu"
      },
      "source": [
        "# hide\n",
        "test_accs = [\n",
        "    64.75,\n",
        "    68.19,\n",
        "    69.0,\n",
        "    65.95,\n",
        "    73.85,\n",
        "    73.78,\n",
        "    76.59,\n",
        "    79.4,\n",
        "    78.45,\n",
        "    79.99,\n",
        "    83.43,\n",
        "    88.24,\n",
        "    89.86,\n",
        "    87.31,\n",
        "    88.02,\n",
        "    88.99,\n",
        "    89.43,\n",
        "    90.39,\n",
        "    89.94,\n",
        "    88.93,\n",
        "    89.93,\n",
        "    92.08,\n",
        "    91.15,\n",
        "    91.77,\n",
        "    89.94,\n",
        "    91.11,\n",
        "    91.43,\n",
        "]\n",
        "max_training_samples = 150\n",
        "acquisition_batch_size = 5\n",
        "num_inference_samples = 100\n",
        "num_test_inference_samples = 5\n",
        "num_samples = 100000\n",
        "num_initial_samples = 20\n",
        "num_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4RpGLCc7jmv"
      },
      "source": [
        "# hide\n",
        "# experiment\n",
        "!pip install matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMkMRGno7jmv"
      },
      "source": [
        "# experiment\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.plot(np.arange(num_initial_samples, max_training_samples + 1, acquisition_batch_size), test_accs)\n",
        "plt.xlabel(\"# training samples\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.hlines(90, 20, 150, linestyles=\"dashed\", color=\"r\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}